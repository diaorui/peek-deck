{
  "subreddit": "robotics",
  "posts": [
    {
      "title": "Robot dance Arduino",
      "author": "Archyzone78",
      "url": "https://www.reddit.com/r/robotics/comments/1pfijsr/robot_dance_arduino/",
      "published": 1765003030.0,
      "thumbnail": "https://external-preview.redd.it/Y25rZXhqYTU0ajVnMbOJhgM30O6ZKO08DBReVskKOrZTZnYgzInYnly_IMMn.png?width=640&crop=smart&auto=webp&s=a5d2610b2998c92abb54372438ed197b1ea3537a",
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": null
    },
    {
      "title": "Sunday Robotics: Collecting Data Through the Memory-Developer Glove Before Building the Humanoid",
      "author": "marwaeldiwiny",
      "url": "https://www.reddit.com/r/robotics/comments/1pf9wv3/sunday_robotics_collecting_data_through_the/",
      "published": 1764976795.0,
      "thumbnail": "https://external-preview.redd.it/cWxrNjVwcmF4ZzVnMbtkBYuAaT2pID18gUmEoHrxBw0Oi--CtM_V6HPif-8k.png?width=640&crop=smart&auto=webp&s=9ce2592a6b294d95ba2654480fa0e1062241b765",
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": "https://youtu.be/UAlm8Z4mfpU"
    },
    {
      "title": "AGIBOT D1 Pro",
      "author": "Nunki08",
      "url": "https://www.reddit.com/r/robotics/comments/1peuynn/agibot_d1_pro/",
      "published": 1764941052.0,
      "thumbnail": "https://external-preview.redd.it/ZGlmbmhkbHR5ZDVnMcmTqcCmyGxlIJwbMAh9zRk_vOBdKNEWQVCUcGUjD1SH.png?width=640&crop=smart&auto=webp&s=8467a4161ee66696616b006012bb7f536eb613b3",
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": "AGIBOT on \ud835\udd4f: AGIBOT D1 Pro/Edu Quadruped Robot is not only a reliable helper for scientific research and education but also an eye-catcher for entertainment companionship and commercial demonstrations\uff5e 3.5m/s fast running, 1-2 hours battery life, IP54 dustproof & waterproof, durable and easy to use!: https://x.com/AgiBot_zhiyuan/status/1996928040182464537"
    },
    {
      "title": "Arduino Nano quadcopter build help",
      "author": "Blorglue",
      "url": "https://www.reddit.com/r/robotics/comments/1pfk3x2/arduino_nano_quadcopter_build_help/",
      "published": 1765008838.0,
      "thumbnail": "https://b.thumbs.redditmedia.com/J3qB6YAlcRqT5TebIymaq3ZrGBWskzTLrHXLiGC70uU.jpg",
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": "Hella everyone! I've been building this drone as my own personal test on my engineering knowledge as I've just finished my mechatronic systems engineering degree. Sorry if the post is too long but here is a TLDR: TLDR: My motors won't spin, arduino logic and wiring should be correct as it worked with an older QBRAIN 4in1 ESC. Suspecting one of my cells in my 3S battery to be dead. Initialization tone is heard but no arming tone and writing esc.writeMicroseconds(1000); in the loop. Also tried 1500us and 2000us. Still doesn't work. ---------------------------------------------------------------------------------------------------- Here is a list of components: Arduion Nano: CH340 chip and ATmega328P ESC: Radiolink FlyColour 4 in 1 ESC (EFM8BB21 MCU, 8-bit C8051 core) Motors: 4x 900Kv BLDC motors (No idea what brand, I just found them) RX/TX: FlySky iA6B receiver and FS-i6X transmitter Gyro: MPU-6050 Buck converter: LM2596 ---------------------------------------------------------------------------------------------------- My setup: I've got the arduino outputting PWM signals into my ESC's motor signal pins which has been mapped to 1000-2000us before being sent into the ESC. (I dont have an oscilloscope to verify) The arduino is powered through the buck converter which sees the full Lipo battery voltage at the input (Stepped down to 5v for the arduino and grounded at arduino gnd) The ESC is powered directly from the Lipo battery and I've connected one of the two grounds leading OUT of the ESC's jst connector into the arduino ground. M1 signal wire is connected to D8 of my arduino and M1 is the only one that is plugged in and powered by the ESC At the moment I just want to be able to command the motor speed through the arduino, no PID control, no serial UART communications just yet. ---------------------------------------------------------------------------------------------------- My Problem: I can hear the motors play the initalization musical tone, but no subsequent beeps for self test or arming and it will not spin. When using the exact same setup on an older QBRAIN 4 in 1 ESC it all worked. Including my PID control and iBUS UART communication. Except the arduino needed to be powered through the ESC's regulator instead of the battery + buck converter combo. ---------------------------------------------------------------------------------------------------- My Theory: One of the 3 cells on my battery is dead, ESC is not getting enough voltage and I'm an idiot ESC boots faster than arduino can and goes into fail safe mode EMI between the logic and power grounds Arduino can't output a fast enough PWM signal If anyone could point me in the right direction to troubleshoot it would be greatly appreciated. I will go buy a new battery in the morning to see if that is the problem. However in the meantime if anyone could point out any wiring issues from what I've described or if you require any more specific information about my setup please let me know. Otherwise feel free to criticize, hate or provide constructive suggestions to my project. ---------------------------------------------------------------------------------------------------- Extra questions: Is the arduino nano even a suitable MCU for this application? From my research it seems like there is not enough of a safety margin in terms of cycles/second to do PID math, read gyro data and send fast PWM signals. If anything is bunged out of order it could lead to a positive feedback loop and crash my drone Since it is an engineering project and not a drone building project I'd like to use something that i can program. What other microcontrollers can work in place of the nano? (Preferrably not something I need to use assembly and design an MCU from scratch, thats a whole another project) https://preview.redd.it/qdwmnaiw9j5g1.jpg?width=3024&format=pjpg&auto=webp&s=f7871ed8a913dcf55e474cf7cdb7787240a3b9c3"
    },
    {
      "title": "Art installation draws attention for its robot dogs with famous faces",
      "author": "nbcnews",
      "url": "https://www.reddit.com/r/robotics/comments/1pe56c3/art_installation_draws_attention_for_its_robot/",
      "published": 1764867378.0,
      "thumbnail": "https://external-preview.redd.it/cTJ2N2RidXF3NzVnMa2NkyWLusU3EEB1G1quIu5uMib9yhFcaTJpvX4KlXi-.png?width=640&crop=smart&auto=webp&s=5c4b356e7b7139ee64c4e5a27f5c0e40298e7324",
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": null
    },
    {
      "title": "Are we witnessing the end of \u201creal robot data\u201d as the foundation of Embodied AI? Recent results from InternData-A1, GEN-0, and Tesla suggest a shift. (Original post by Felicia)",
      "author": "Individual-Major-309",
      "url": "https://www.reddit.com/r/robotics/comments/1pessi4/are_we_witnessing_the_end_of_real_robot_data_as/",
      "published": 1764934446.0,
      "thumbnail": "https://a.thumbs.redditmedia.com/xYGdExuacIcgGtMT_4UoS63x2i1kRFGFAmyDCxoBwi4.jpg",
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": "For a long time, many robotics teams believed that real robot interaction data was the only reliable foundation for training generalist manipulation models. But real-world data collection is extremely expensive, slow, and fundamentally limited by human labor. Recent results suggest the landscape is changing. Three industry signals stand out: 1. InternData-A1: Synthetic data beats the strongest real-world dataset Shanghai AI Lab\u2019s new paper InternData-A1 (Nov 2025, arXiv) is the first to show that pure simulation data can match or outperform the best real-robot dataset used to train Pi0. The dataset is massive: 630k+ trajectories 7,434 hours 401M frames 4 robot embodiments, 18 skill types, 70 tasks $0.003 per trajectory generation cost One 8\u00d7RTX4090 workstation \u2192 200+ hours of robot data per day Results: On RoboTwin2.0 (49 bimanual tasks): +5\u20136% success over Pi0 On 9 real-world tasks: +6.2% success Sim-to-Real: 1,600 synthetic samples \u2248 200 real samples (\u22488:1 efficiency) The long-held \u201csimulation quality discount\u201d is shrinking fast. 2. GEN-0 exposes the economic impossibility of scaling real-world teleoperation Cross-validated numbers show: Human teleoperation cost per trajectory: $2\u2013$10 Hardware systems: $30k\u2013$40k 1 billion trajectories \u2192 $2\u201310 billion GEN-0\u2019s own scaling law predicts that laundry alone would require 1B interactions for strong performance. https://preview.redd.it/qd8pkcdpfd5g1.png?width=556&format=png&auto=webp&s=1df2607476d3e63f5ca32edae1bf7319d97f1176 Even with Tesla-level resources, this is not feasible. That\u2019s why GEN-0 relies on distributed UMI collection across thousands of sites instead of traditional teleoperation. 3. Tesla\u2019s Optimus shifts dramatically: from mocap \u2192 human video imitation Timeline: 2022\u20132024: Tesla used full-body mocap suits + VR teleop; operators wore ~30 lb rigs, walked 7 hours/day, paid up to $48/hr. May 21, 2025: Tesla confirms:\u201cOptimus is now learning new tasks directly from human videos.\u201d June 2025: Tesla transitions to a vision-only approach, dropping mocap entirely. Their demo showed Optimus performing tasks like trash disposal, vacuuming, cabinet/microwave use, stirring, tearing paper towels, sorting industrial parts \u2014 all claimed to be controlled by a single end-to-end network. 4. So is real robot data obsolete? Not exactly. These developments indicate a shift, not a disappearance: Synthetic data (InternData-A1) is now strong enough to pre-train generalist policies Distributed real data (GEN-0) remains critical for grounding and calibration Pure video imitation (Tesla) offers unmatched scalability but still needs validation for fine manipulation All major approaches still rely on a small amount of real data for fine-tuning or evaluation Open Questions: Where do you think the field is heading? A synthetic-first paradigm? Video-only learning at scale? Hybrid pipelines mixing sim, video, and small real datasets? Or something entirely new? Curious to hear perspectives from researchers, roboticists, and anyone training embodied agents."
    },
    {
      "title": "Chat Interface for Isaac Sim",
      "author": "wasabidino",
      "url": "https://www.reddit.com/r/robotics/comments/1pfa7jb/chat_interface_for_isaac_sim/",
      "published": 1764977565.0,
      "thumbnail": null,
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": null
    },
    {
      "title": "Behind-the-scenes footage from the EngineAI T800 shoot \u2014 a direct response to the CG accusations.",
      "author": "Ready_Device8994",
      "url": "https://www.reddit.com/r/robotics/comments/1peipg7/behindthescenes_footage_from_the_engineai_t800/",
      "published": 1764899968.0,
      "thumbnail": "https://external-preview.redd.it/vopCp3AoP3agRM_vVjx1qGQ2dEK42KQd5nQEj5DdiQA.jpeg?width=320&crop=smart&auto=webp&s=b4c4505fe2c220f8942da9db848c634ecdba635b",
      "external_url": "https://www.youtube.com/watch?v=VoytjBgpG28",
      "site_name": "youtube.com",
      "favicon": "https://www.youtube.com/s/desktop/db7db827/img/favicon.ico",
      "description": "Enjoy the videos and music you love, upload original content, and share it all with friends, family, and the world on YouTube."
    },
    {
      "title": "ROS News for the Week of December 2nd, 2025",
      "author": "OpenRobotics",
      "url": "https://www.reddit.com/r/robotics/comments/1pf5ccu/ros_news_for_the_week_of_december_2nd_2025/",
      "published": 1764965493.0,
      "thumbnail": "https://external-preview.redd.it/ZRxQSYvz7RK70LarVkZ0JsNr2rRueei96seBmDJoatU.gif?width=640&crop=smart&s=480960cabf1c914aa731ede8c40bec3c3fb4a693",
      "external_url": "https://discourse.openrobotics.org/t/ros-news-for-the-week-of-december-2nd-2025/51298",
      "site_name": "Open Robotics Discourse",
      "favicon": "https://us1.discourse-cdn.com/flex022/uploads/ros/optimized/3X/4/4/4487d2db196c8ca556e8bfac980ed3850ba5cbd5_2_180x180.png",
      "description": "ROS News for the Week of December 2nd, 2025     ROSCon 2025 videos are now available! If you want a quick summary of the event I put together ROSCon 2025 Recap for the OpenCV Weekly Webinar.       For Giving Tuesday we put together a new campaign for ROS users to become a become a Build Farm Backer. If you\u2019ve every saved a few minutes by running sudo apt install ros-kilted-* instead of compiling from source we would love it if you helped cover our compute costs. Also, for the first time ever, we..."
    },
    {
      "title": "Making a Marauder's Map from Harry Potter",
      "author": "davesarmoury",
      "url": "https://www.reddit.com/r/robotics/comments/1pf1agl/making_a_marauders_map_from_harry_potter/",
      "published": 1764956101.0,
      "thumbnail": "https://external-preview.redd.it/lkbyF5afhW6Htup7fUyNQVABCSEpJ946WVXQNrql7uM.jpeg?width=320&crop=smart&auto=webp&s=7bd8c748c2ede63e1e653ef9114a146b3f7c00ea",
      "external_url": "https://www.youtube.com/watch?v=dO32ImnsX-4",
      "site_name": "youtube.com",
      "favicon": "https://www.youtube.com/s/desktop/db7db827/img/favicon.ico",
      "description": "Arthur C. Clarke said \"Any sufficiently advanced technology is indistinguishable from magic\". This is the perfect example of that. We are taking a magical map that previously could only exist in a magical world and bringing it to life using robots, DeepStream, and multiple A6000 GPUs!"
    }
  ],
  "fetched_at": "2025-12-06T09:20:54.502914+00:00"
}