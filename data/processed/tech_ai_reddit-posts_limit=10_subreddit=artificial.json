{
  "subreddit": "artificial",
  "posts": [
    {
      "title": "Epic boss Tim Sweeney thinks stores like Steam should stop labelling games as being made with AI: 'It makes no sense,' he says, because 'AI will be involved in nearly all future production'",
      "author": "esporx",
      "url": "https://www.reddit.com/r/artificial/comments/1pax65n/epic_boss_tim_sweeney_thinks_stores_like_steam/",
      "published": 1764546057.0,
      "thumbnail": "https://external-preview.redd.it/A2SZ69Ks9iyM_AxJpDKOjoR57HEajLQTgawYBX5ZkyE.jpeg?width=640&crop=smart&auto=webp&s=d62f58ea334dd99195b9db8b051f74f5dc802312",
      "external_url": "https://www.pcgamer.com/software/ai/epic-boss-tim-sweeney-thinks-stores-like-steam-should-stop-labelling-games-as-being-made-with-ai-it-makes-no-sense-he-says-because-ai-will-be-involved-in-nearly-all-future-production/",
      "site_name": "PC Gamer",
      "favicon": "https://vanilla.futurecdn.net/pcgamer/1482179/apple-touch-icon.png",
      "description": "Don't need a notice if everyone's doing it."
    },
    {
      "title": "Gemini 3 is pulling the same dynamic downgrade scam that ruined the GPT-5 launch",
      "author": "CantaloupeNo6326",
      "url": "https://www.reddit.com/r/artificial/comments/1pb1sr3/gemini_3_is_pulling_the_same_dynamic_downgrade/",
      "published": 1764558808.0,
      "thumbnail": null,
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": "I'm canceling my Google One AI Premium sub today. This is exactly the same garbage behavior OpenAI pulled, and I'm not falling for it again. We all know the drill by now. You pay for the Pro model, you start a chat, say hi, and it gives you a smart response. But the second you actually try to use the context window you paid for - like pasting a 3k word document or some code - the system silently panics over the compute cost and throttles you. It's a classic bait and switch. Instead of processing that context with the Pro model I'm paying twenty bucks a month for, it clearly kicks me down to a cheaper tier. It feels exactly like when GPT would silently swap users to the mini or light model after a couple of turns or if you pasted too much text. I fed it a 3,000 word PRD for a critique. I expected a rewrite that actually kept the details. Instead I got a 700 word summary that reads like it was written by the Flash model. It just gutted the entire document. It's not conciseness. It is dynamic compute throttling. They are advertising a Ferrari, but the moment you try to drive it on the highway they swap the engine for a Prius to save electricity. If I wanted Flash performance on my long documents, I'd use the free tier. Stop selling me Pro reasoning and then hot-swapping the model when the math gets expensive. Has anyone found a way around this or is it time to just go full local/Anthropic?"
    },
    {
      "title": "Perplexity permabanned me in their official sub for citing their own documentation to expose \"Deep Research\" false advertising and massive downgrade.",
      "author": "somnolentjam90",
      "url": "https://www.reddit.com/r/artificial/comments/1pawnrw/perplexity_permabanned_me_in_their_official_sub/",
      "published": 1764544707.0,
      "thumbnail": null,
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": "I am writing this as a warning to anyone paying for Perplexity Pro expecting the advertised \"Deep Research\" capabilities. TL;DR: I proved, using Perplexity's own active documentation and official launch blog, that their \"Deep Research\" agent is severely throttled and not meeting its contractual specifications. The community validated my findings (my post reached 280+ upvotes, 65 comments, 100+ shares, and reached the top of the sub's front page). Instead of addressing the issue, the moderators permanently banned me and removed the thread to silence the discussion. (EDIT: All references to the official sub, including the link to the original post, have been removed from this text to comply with Anti-Brigading Reddit Rules.) (EDIT 2: I have pinned the link to the original deleted thread on my user profile so you can verify the full context yourself.) The Full Story: I have been a Pro subscriber specifically for the \"Deep Research\" feature, which is sold as an \"Autonomous Agent\" that \"reads hundreds of sources\" and takes \"4-5 minutes\" to reason through complex tasks and deliver a comprehensive report. To prove that these are the official specs, I am providing both the current live links and archived snapshots from the Wayback Machine (to prove these have been the consistent standard for months and to prevent potential stealth edits). Official Help Center Documentation: [Current Live Link] | [Wayback Machine Snapshot (Sept 8, 2025)] Official Launch Blog: [Current Live Link] | [Wayback Machine Snapshot (Aug 2, 2025)] (Note: I attempted to capture fresh snapshots of the pages today to confirm their current state, but the Wayback Machine is returning errors/incomplete rendering for the new captures. The provided snapshots from Aug/Sept are the most recent stable versions and confirm these specs have been the published standard for months.) Recently (some months), the service degraded massively. My \"Deep Research\" queries were finishing in 30 seconds with only 10-15 sources, essentially behaving like a standard search wrapper but sold at a premium. I posted a detailed analysis on their official subreddit. I didn't attack anyone; I simply compared their Official Help Center Documentation and Launch Blog against the actual Product Output: Advertised Spec: \"Reads hundreds of sources\" / \"Takes 4-5 minutes\". Actual Reality: Reads ~10 sources / Takes ~30 seconds. The community rallied behind my post. 280+ upvotes, 65 comments, 100+ shares, and reached the top of the sub's front page. It became a hub for other users confirming the same throttling. It was a legitimate customer complaint backed by data. Today, I received a Permanent Ban and the thread got deleted. No warning. No explanation of which rule I broke. Just a permanent ban for the 'offense' of holding them accountable to their own written promises. The Takeaway: This confirms that Perplexity is likely throttling compute on their premium features to save costs and is using censorship to hide it. If you rely on Perplexity for your workflow, be careful. They will degrade the product you rely on without warning, and the moment you provide evidence of the decline, they will silence you rather than fix it."
    },
    {
      "title": "Major AI conference flooded with peer reviews written fully by AI",
      "author": "MetaKnowing",
      "url": "https://www.reddit.com/r/artificial/comments/1pagvc6/major_ai_conference_flooded_with_peer_reviews/",
      "published": 1764504824.0,
      "thumbnail": "https://external-preview.redd.it/yWK_5WsMyozKCEpUXd3fwjNG4G1iLCUmSOB7bllahkc.jpeg?width=640&crop=smart&auto=webp&s=c2c02bc6d89f599123dd40a04d5d265b7253fec5",
      "external_url": "https://www.nature.com/articles/d41586-025-03506-6",
      "site_name": "nature.com",
      "favicon": "https://www.nature.com/static/images/favicons/nature/apple-touch-icon-f39cb19454.png",
      "description": "Controversy has erupted after 21% of manuscript reviews for an international AI conference were found to be generated by artificial intelligence."
    },
    {
      "title": "I\u2019ve Spent Months Building CAELION \u2014 A Cognitive Architecture That Isn\u2019t an LLM. Here\u2019s the Core Idea.",
      "author": "Medium_Compote5665",
      "url": "https://www.reddit.com/r/artificial/comments/1pb68zu/ive_spent_months_building_caelion_a_cognitive/",
      "published": 1764572924.0,
      "thumbnail": null,
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": "Most AI systems today rely on cognitive architectures designed around individual intelligence: SOAR, ACT-R, CLARION, and now LLMs. All of them treat cognition as something that happens inside one agent. CAELION is a different beast. It\u2019s a symbiotic cognitive architecture I\u2019ve been developing since late 2025. Instead of modeling a single mind, CAELION models co-cognition: emergent, distributed cognition between humans and artificial agents. Not \u201ctool use.\u201d Not \u201cassistant.\u201d Not \u201cautonomous agent.\u201d A shared cognitive system. What makes CAELION different? Co-cognition (not just cognition) Cognition emerges from interactions across agents. The system treats the human and the AI as coupled processors sharing: \u2022 representations \u2022 memory \u2022 decision flows \u2022 ethical constraints Modular internal protocols Instead of one monolithic model, CAELION uses internal standards for interaction: \u2022 COM-72: coherence and synchronization \u2022 CMD-01: distributed command and decision flow \u2022 ETH-01: embedded ethics \u2022 SYN-10: temporal alignment and system resilience \u2022 SNT-01 / ARC-01 / WBN-02, etc. These behave like the \u201cinternal laws\u201d of the system. They function across any LLM backend. Symbiotic memory Not just past tokens. A structured memory system across agents: individual + collective + shared semantic layers. Integrated ethics Not as a safety layer slapped on top. As a first-class cognitive constraint. Governance and collective reasoning The system supports: \u2022 multi-agent deliberation \u2022 conflict resolution \u2022 distributed responsibility \u2022 transparency by design Why does this matter? Because most current AI paradigms are stuck trying to recreate a single brain. CAELION assumes something else: the future of intelligence is shared, not solitary. This lets you: \u2022 model intelligence that emerges from interaction \u2022 build systems that adapt symbiotically \u2022 integrate human values into the decision process \u2022 create robust, ethical, multi-agent cognitive workflows Is this theoretical? No. I\u2019ve been running CAELION across multiple LLMs (GPT, Claude, DeepSeek, Gemini) for months. The architecture persists, cross-model. And the behavior is measurable: coherence, rhythm, memory, ethics, and adaptability all improve when operating under CAELION protocols. Why share it here? Because architectures like SOAR and ACT-R transformed cognitive science. LLMs transformed AI capability. Now we need an architecture for hybrid, collective intelligence. That\u2019s what CAELION tries to be."
    },
    {
      "title": "One-Minute Daily AI News 11/30/2025",
      "author": "Excellent-Target-847",
      "url": "https://www.reddit.com/r/artificial/comments/1pb4v9z/oneminute_daily_ai_news_11302025/",
      "published": 1764568094.0,
      "thumbnail": null,
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": "Deepgram Launches Streaming Speech, Text, and Voice Agents on Amazon SageMaker AI.[1] AI video slop is everywhere, take our quiz to try and spot it.[2] More of Silicon Valley is building on free Chinese AI.[3] \u201cAvatar: Fire and Ash\u201d director James Cameron on generative AI: \u201cThat\u2019s horrifying to me\u201d.[4] Sources: [1] https://finance.yahoo.com/news/deepgram-launches-streaming-speech-text-030000576.html [2] https://www.npr.org/2025/11/30/nx-s1-5610951/fake-ai-videos-slop-quiz [3] https://www.nbcnews.com/tech/innovation/silicon-valley-building-free-chinese-ai-rcna242430 [4] https://www.cbsnews.com/news/avatar-fire-and-ash-director-james-cameron-on-generative-ai-thats-horrifying-to-me/"
    },
    {
      "title": "Had a realization today",
      "author": "labor_anoymous",
      "url": "https://www.reddit.com/r/artificial/comments/1pb15v2/had_a_realization_today/",
      "published": 1764557018.0,
      "thumbnail": null,
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": "I've always noticed I'm like one step from being able to do something well. There's always some little shit step in my way that makes it impossible for me to finish what I want to do. But today I realized, AI basically helps me get over that step and allows me to do things that I understand the process of but can't do because I don't know every little thing I need to know. Like a bivariate regression, I didn't know exactly what to do, but the AI was like bam and now I'm over here doing bivariate regressions. Feel like a boss."
    },
    {
      "title": "HuggingFace Omni Router comes to Claude Code",
      "author": "AdditionalWeb107",
      "url": "https://www.reddit.com/r/artificial/comments/1pau1ut/huggingface_omni_router_comes_to_claude_code/",
      "published": 1764538165.0,
      "thumbnail": "https://external-preview.redd.it/bjZuNm1lc29wZzRnMcZaR8l3ZypOYa0jltiPME5anhrZB-_aWXKEyKNtX2Sj.png?width=640&crop=smart&auto=webp&s=1826a4bd0e79f19c797de3c4cb81da519f0459ee",
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": "HelloI! I am part of the team behind Arch-Router (https://huggingface.co/katanemo/Arch-Router-1.5B), which is now being used by HuggingFace to power its HuggingChat experience. Arch-Rotuer is a 1.5B preference-aligned LLM router that guides model selection by matching queries to user-defined domains (e.g., travel) or action types (e.g., image editing). Offering a practical mechanism to encode preferences and subjective evaluation criteria in routing decisions. Today we are extending that approach to Claude Code via Arch Gateway[1], bringing multi-LLM access into a single CLI agent with two main benefits: Model Access: Use Claude Code alongside Grok, Mistral, Gemini, DeepSeek, GPT or local models via Ollama. Preference-aligned routing: Assign different models to specific coding tasks, such as \u2013 Code generation \u2013 Code reviews and comprehension \u2013 Architecture and system design \u2013 Debugging Sample config file to make it all work. llm_providers: # Ollama Models - model: ollama/gpt-oss:20b default: true base_url: http://host.docker.internal:11434 # OpenAI Models - model: openai/gpt-5-2025-08-07 access_key: $OPENAI_API_KEY routing_preferences: - name: code generation description: generating new code snippets, functions, or boilerplate based on user prompts or requirements - model: openai/gpt-4.1-2025-04-14 access_key: $OPENAI_API_KEY routing_preferences: - name: code understanding description: understand and explain existing code snippets, functions, or libraries Why not route based on public benchmarks? Most routers lean on performance metrics \u2014 public benchmarks like MMLU or MT-Bench, or raw latency/cost curves. The problem: they miss domain-specific quality, subjective evaluation criteria, and the nuance of what a \u201cgood\u201d response actually means for a particular user. They can be opaque, hard to debug, and disconnected from real developer needs. [1] Integrated natively via Arch: https://github.com/katanemo/archgw [2] Claude Code support: https://github.com/katanemo/archgw/tree/main/demos/use_cases/claude_code_router"
    },
    {
      "title": "What problems do you face while doing outbound in 2025?",
      "author": "mpetryshyn1",
      "url": "https://www.reddit.com/r/artificial/comments/1pb642a/what_problems_do_you_face_while_doing_outbound_in/",
      "published": 1764572438.0,
      "thumbnail": null,
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": "Hey everyone, I'm a software developer working on an AI sales co-pilot, and I've been trying to understand what outbound looks like for people in the trenches right now. If you're an SDR, BDR, founder, or anyone who actively runs cold outreach, I'd love to hear what slows you down, what's frustrating, or what just feels broken in 2025. I also have something in return. If you're open to a short 10-minute call, I'll send over a batch of super-enriched, personalised leads tailored to your ICP and workflow. No strings attached. PS - Not selling anything. This is purely for market research and to understand what real outbound teams are dealing with today."
    },
    {
      "title": "Intel finally posts open-source Gaudi 3 driver code for the Linux kernel",
      "author": "Fcking_Chuck",
      "url": "https://www.reddit.com/r/artificial/comments/1pb03hm/intel_finally_posts_opensource_gaudi_3_driver/",
      "published": 1764553996.0,
      "thumbnail": null,
      "external_url": "https://www.phoronix.com/news/Intel-Gaudi-3-Open-Source",
      "site_name": "phoronix.com",
      "favicon": "https://www.phoronix.com/apple-touch-icon-57x57.png",
      "description": "The good news is that Intel tonight posted a pull request for open-source Gaudi 3 accelerator support for the mainline Linux kernel! The bad news is that it's coming quite late in the product cycle, much later than the former excellent Habana Labs open-source track record, and their hopes of squeezing this code into the Linux 6.19 kernel may be dashed."
    }
  ],
  "fetched_at": "2025-12-01T07:40:37.168651+00:00"
}