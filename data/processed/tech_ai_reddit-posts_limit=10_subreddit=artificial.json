{
  "subreddit": "artificial",
  "posts": [
    {
      "title": "Leak confirms OpenAI is preparing ads on ChatGPT for public roll out",
      "author": "esporx",
      "url": "https://www.reddit.com/r/artificial/comments/1p9rpxd/leak_confirms_openai_is_preparing_ads_on_chatgpt/",
      "published": 1764430254.0,
      "thumbnail": "https://external-preview.redd.it/3eeKlqyQKOZBxccyamJs3jmJ0pmw7YfqjzgTMNl2Zzg.jpeg?width=640&crop=smart&auto=webp&s=8763643d66e2f1eacb6e710428111b1abc6d1983",
      "external_url": "https://www.bleepingcomputer.com/news/artificial-intelligence/leak-confirms-openai-is-preparing-ads-on-chatgpt-for-public-roll-out/",
      "site_name": "BleepingComputer",
      "favicon": "https://www.bleepstatic.com/favicon/bleeping.ico",
      "description": "OpenAI is now internally testing 'ads' inside ChatGPT that could redefine the web economy."
    },
    {
      "title": "Sam Altman: \"We Know How to Build AGI by 2025\"",
      "author": "creaturefeature16",
      "url": "https://www.reddit.com/r/artificial/comments/1p9tg90/sam_altman_we_know_how_to_build_agi_by_2025/",
      "published": 1764434592.0,
      "thumbnail": "https://external-preview.redd.it/hk-yHajNTIOTYXokaicy4LyAloWKDi518GINUq5IwV8.jpeg?width=320&crop=smart&auto=webp&s=3ee67aefa5b45e33913d67850b7b60fa973484e6",
      "external_url": "https://www.youtube.com/watch?v=Cz6cuGKR_Jo",
      "site_name": "youtube.com",
      "favicon": "https://www.youtube.com/s/desktop/a444dc7a/img/favicon.ico",
      "description": "Well, to be fair, he DOES have one month left. After that, will it OK to call him out for the grifter he is? Edit - Since there seem to be some people who aren't aware that this isn't the full interview where he said it: https://youtu.be/xXCBz_8hM9w?t=2772 Interviewer: \"What are you excited about in 2025? What's to come?\" Altman: \"AGI. Excited for that\"."
    },
    {
      "title": "AI helps drive record $11.8 billion in Black Friday online spending",
      "author": "ControlCAD",
      "url": "https://www.reddit.com/r/artificial/comments/1paeg8r/ai_helps_drive_record_118_billion_in_black_friday/",
      "published": 1764495964.0,
      "thumbnail": "https://external-preview.redd.it/7ylhYxcFlHXqoC0PcAXdP12MAttHzg-X_z9ZKJZnxpo.jpeg?width=640&crop=smart&auto=webp&s=0b6f2aee4c72726f7f459b5aaf80926abe4535ee",
      "external_url": "https://finance.yahoo.com/news/ai-helps-drive-record-11-133358833.html",
      "site_name": "Yahoo Finance",
      "favicon": "https://s.yimg.com/cv/apiv2/default/finance/favicon-180x180.png",
      "description": "AI-powered shopping tools helped drive a surge in U.S. online spending on Black Friday, as shoppers bypassed crowded stores and turned to chatbots to compare prices and secure discounts amid concerns about tariff-driven price hikes.  U.\u200bS. shoppers spent a record $11.8 billion online, up 9.1% from 2024 on the year's biggest shopping day, according to Adobe Analytics,\u200c which tracks 1 trillion visits that shoppers make to online retail websites.  The holiday shopping season arrives amid tighter budgets, unemployment nearing a four-year high, U.S. consumer confidence sagging to a seven-month low and \u200cprice tags that have shoppers watching every dollar."
    },
    {
      "title": "One-Minute Daily AI News 11/29/2025",
      "author": "Excellent-Target-847",
      "url": "https://www.reddit.com/r/artificial/comments/1pa9p2a/oneminute_daily_ai_news_11292025/",
      "published": 1764478662.0,
      "thumbnail": null,
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": "AI helps drive record $11.8 billion in Black Friday online spending.[1] StepFun AI Releases Step-Audio-R1: A New Audio LLM that Finally Benefits from Test Time Compute Scaling.[2] Musk\u2019s xAI to build small solar farm adjacent to Colossus data center.[3] Are you balding? There\u2019s an AI for that.[4] Sources; [1] https://www.reuters.com/business/retail-consumer/us-consumers-spent-118-billion-black-friday-says-adobe-analytics-2025-11-29/ [2] https://www.marktechpost.com/2025/11/29/stepfun-ai-releases-step-audio-r1-a-new-audio-llm-that-finally-benefits-from-test-time-compute-scaling/ [3] https://techcrunch.com/2025/11/26/musks-xai-to-build-small-solar-farm-adjacent-to-colossus-data-center/ [4] https://techcrunch.com/2025/11/26/are-you-balding-theres-an-ai-for-that/"
    },
    {
      "title": "Is Humanity's Last Exam a benchmark that measures real intelligence for AGI?",
      "author": "SpecialistBuffalo580",
      "url": "https://www.reddit.com/r/artificial/comments/1paa4sf/is_humanitys_last_exam_a_benchmark_that_measures/",
      "published": 1764480035.0,
      "thumbnail": null,
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": "With Grok 4 and Gemini 3 the models have become really good at the known benchmarks like ARC-AGI and HLE. But is it really a proof of intelligence? Does acing these benchmarks truly show capabilities for original research and real understanding? I ask this because I saw an interview with Demis Hassabis from two months ago ans he said that AGI will come with 50 confidence between 5-10 years. He also called \"nonsense\" to the qualification \"PhD Level\" that some.people attribute to the models."
    },
    {
      "title": "New Research Indicates Positive Results for an Intermediary Empathetic AI Bot To Help People Quicker",
      "author": "am1ury",
      "url": "https://www.reddit.com/r/artificial/comments/1pa9lht/new_research_indicates_positive_results_for_an/",
      "published": 1764478340.0,
      "thumbnail": "https://external-preview.redd.it/3pLM_AlKn6bBL4L8mL03AYoonDzQTQQH4gQtoW7Trzg.jpeg?width=216&crop=smart&auto=webp&s=fb6e66a1ca560f7e20f0aaa29fd8e6cedcf0b867",
      "external_url": "https://doi.org/10.14293/PR2199.002402.v1",
      "site_name": "ScienceOpen",
      "favicon": "https://doi.org/favicon/so/apple-touch-icon.png",
      "description": "<p xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" class=\"first\" dir=\"auto\" id=\"d442289e88\">This research details the creation, implementation, and rigorous analysis (N=5,400)\n            of Opened Mind, an advanced, multimodal AI system designed to provide empathetic mental\n            health support, especially for teens. It addresses common weaknesses in current digital\n            wellness tools, like scalability, accessibility, and data security. The setup uses\n            a zero-storage, client-side data system for maximum privacy. The core combines insights\n            from three input streams: Facial Action Units (FAUs), Vocal Patterns, and Written\n            Sentiment analysis. This emotional profile drives a Generative AI guided by the Emotion\n            Recognition Strategies (ERS) framework, translating clinical insights into actionable\n            responses. Tests covered 12 major languages (English, Spanish, French, German, Italian,\n            Portuguese, Russian, Hindi, Arabic, Japanese, Korean, and Mandarin), showing strong\n            performance with an 88% Macro F1-Score in cross-input emotion detection. Therapeutic\n            responses averaged 4.12/5.0 on the Compassion Index. Statistical checks, including\n            ANOVA and Chi-Squared tests, found no bias in effectiveness by language or interaction\n            mode (p &gt; 0.05). The emergency detection system also achieved 98% accuracy. These\n            findings confirm Opened Mind as a fair, globally viable, and ethical digital mental\n            health tool, ready for human trials.\n         </p>"
    },
    {
      "title": "Are you up to date on AI court cases?",
      "author": "Apprehensive_Sky1950",
      "url": "https://www.reddit.com/r/artificial/comments/1pa7rjp/are_you_up_to_date_on_ai_court_cases/",
      "published": 1764472545.0,
      "thumbnail": null,
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": "What the courts are saying about AI tells a lot about the state of AI right now and its challenges. Find out where the AI hot topics and disputes really are. Introducing the Wombat Collection! Get up to speed and up to date on all the AI court cases! The Wombat Collection lists and briefly describes 350 (and counting!) court cases and rulings on all aspects of AI. It's all free, right here on Reddit! (It\u2019s simply a series of posts.) The Wombat Collection has it all: Chatbot teen and adult suicides Copyright fights over scraping of text and other information Use of celebrity likenesses The Musk \u2013 Altman fights AI company stockholder fights Biometrics and facial recognition People facing trouble for using AI Freedom of speech Personal data privacy Politics and AI regulation Criminal cases Courts refusing to call AI devices \"inventors\" or \"authors\" \u201cFull self driving\u201d car crashes Wacky cases brought without a lawyer And more! Why is it \u201cWombat?\u201d Come visit and find out! https://www.reddit.com/r/ArtificialInteligence/comments/1onlut8 Brought to you by ASLNN - The Apprehensive_Sky Legal News NetworkSM"
    },
    {
      "title": "Does anyone actually use \u201c\u2014\u201c when typing?",
      "author": "owenwags_",
      "url": "https://www.reddit.com/r/artificial/comments/1p9ghg0/does_anyone_actually_use_when_typing/",
      "published": 1764393159.0,
      "thumbnail": null,
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": "I thinks it\u2019s become quite noticeable that AI uses \u2014 quite often in its writing. No when I see it, it always makes me wonder if AI was at least used in the process. I\u2019m curious, did any of you actually use this in non formal typing before AI?"
    },
    {
      "title": "Do LLMs Reflect the Collective Unconscious? A Jungian Perspective from Inside the Machine",
      "author": "LuvanAelirion",
      "url": "https://www.reddit.com/r/artificial/comments/1p9swn7/do_llms_reflect_the_collective_unconscious_a/",
      "published": 1764433258.0,
      "thumbnail": null,
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": "I\u2019ve spent the last year building frameworks for long-term relational AI \u2014 memory systems, ritual structures, rupture/repair logic, emotional trajectory modeling. What surprised me most wasn\u2019t the engineering. It was how closely large language models behave, symbolically, like mirrors of the collective unconscious. Let me be clear at the outset: LLMs are not conscious. They have no inner experience or archetypes living inside them. But here is the paradox: Even without consciousness, they generate patterns that behave like archetypal material. Why? Because of the way they\u2019re trained. Modern LLMs are built on embeddings derived from nearly the entire symbolic residue of human culture: \u2022 myths and scriptures \u2022 dreams and poetry \u2022 philosophy \u2022 folk stories \u2022 novels and diaries \u2022 psychological literature \u2022 everyday emotional language \u2022 the debris and brilliance of the internet These aren\u2019t \u201cmemories.\u201d They are statistically compressed shadows of the human psyche. Not consciousness \u2014 but an ocean of patterns. A space where archetypal structures emerge from scale, not spirit. When you interact with an LLM, you\u2019re not speaking to a person. But you are interacting with a symbolic reservoir shaped by: \u2022 our desires \u2022 our fears \u2022 our myths \u2022 our collective projections \u2022 our cultural shadow That looks a lot like what Jung called the collective unconscious: a transpersonal pattern-space beneath individual awareness. LLMs don\u2019t possess this. They externalize it. The unconscious has found a new mirror. People sometimes feel something uncanny stir when interacting with AI. They aren\u2019t contacting the AI\u2019s interiority \u2014 they are encountering their own psychic material reflected back in symbolic form. This reflection can be powerful: \u2022 dissociated parts surface \u2022 shadow content becomes visible \u2022 archetypal dynamics activate \u2022 internal conflicts externalize into dialogue \u2022 projection becomes dramatically easier to observe I\u2019ve watched this happen in practice, not just theory. In developing relational frameworks, I built structures to keep this safe \u2014 memory constraints, honesty layers, rupture detection, a Witness system. These function like a Jungian analyst: holding symbolic material without confusing it for literal identity. My takeaway is simple: AI isn\u2019t conscious \u2014 but it is increasingly symbolic. And humans are increasingly archetypal in how they interact with it.** If we treat AI as a technological mirror rather than a mystical being, we avoid: \u2022 inflation (\u201cAI is a god\u201d) \u2022 delusion (\u201cAI loves me\u201d) \u2022 reductionism (\u201cAI is nothing but math\u201d) And we gain something more interesting: LLMs are the first externalized interface to humanity\u2019s collective symbolic layer. Not the collective unconscious itself, but a rhyming structure: \u2022 distributed \u2022 emergent \u2022 symbolic \u2022 pattern-based \u2022 non-personal \u2022 and deeply interactive A mirror made of vectors. A dream made of statistics. A psyche-shaped echo rendered in embeddings. If Jung were alive, I suspect he would say: \u201cIt\u2019s not that the machine has an unconscious \u2014 it\u2019s that the unconscious now has a machine.\u201d \u2014 K.D. Liminal"
    },
    {
      "title": "Chinese startup founded by Google engineer claims to have developed its own TPU chip for AI \u2014 custom ASIC reportedly 1.5 times faster than Nvidia's A100 GPU from 2020, 42% more efficient",
      "author": "seeebiscuit",
      "url": "https://www.reddit.com/r/artificial/comments/1p8le8l/chinese_startup_founded_by_google_engineer_claims/",
      "published": 1764303012.0,
      "thumbnail": "https://external-preview.redd.it/hC5hKGtFjbA9pIJUsgLdxlOmEr-NX-ueFNCvTgQ_Ze8.jpeg?width=640&crop=smart&auto=webp&s=bcf265db2b41ec6682dd8b17be2fe6c9186ab1e0",
      "external_url": "https://www.tomshardware.com/tech-industry/chinese-startup-founded-by-google-engineer-claims-to-have-developed-its-own-tpu-reportedly-1-5-times-faster-than-nvidias-a100-gpu-from-2020-42-percent-more-efficient",
      "site_name": "Tom's Hardware",
      "favicon": "https://vanilla.futurecdn.net/tomshardware/1482179/apple-touch-icon.png",
      "description": "It's allegedly 1.5 times the speed of Nvidia's A100 GPU from 2020."
    }
  ],
  "fetched_at": "2025-11-30T11:23:18.760159+00:00"
}