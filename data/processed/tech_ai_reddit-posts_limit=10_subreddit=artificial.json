{
  "subreddit": "artificial",
  "posts": [
    {
      "title": "Major AI conference flooded with peer reviews written fully by AI",
      "author": "MetaKnowing",
      "url": "https://www.reddit.com/r/artificial/comments/1pagvc6/major_ai_conference_flooded_with_peer_reviews/",
      "published": 1764504824.0,
      "thumbnail": "https://external-preview.redd.it/yWK_5WsMyozKCEpUXd3fwjNG4G1iLCUmSOB7bllahkc.jpeg?width=640&crop=smart&auto=webp&s=c2c02bc6d89f599123dd40a04d5d265b7253fec5",
      "external_url": "https://www.nature.com/articles/d41586-025-03506-6",
      "site_name": "nature.com",
      "favicon": "https://www.nature.com/static/images/favicons/nature/apple-touch-icon-f39cb19454.png",
      "description": "Controversy has erupted after 21% of manuscript reviews for an international AI conference were found to be generated by artificial intelligence."
    },
    {
      "title": "HuggingFace Omni Router comes to Claude Code",
      "author": "AdditionalWeb107",
      "url": "https://www.reddit.com/r/artificial/comments/1pau1ut/huggingface_omni_router_comes_to_claude_code/",
      "published": 1764538165.0,
      "thumbnail": "https://external-preview.redd.it/bjZuNm1lc29wZzRnMcZaR8l3ZypOYa0jltiPME5anhrZB-_aWXKEyKNtX2Sj.png?width=640&crop=smart&auto=webp&s=1826a4bd0e79f19c797de3c4cb81da519f0459ee",
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": "HelloI! I am part of the team behind Arch-Router (https://huggingface.co/katanemo/Arch-Router-1.5B), which is now being used by HuggingFace to power its HuggingChat experience. Arch-Rotuer is a 1.5B preference-aligned LLM router that guides model selection by matching queries to user-defined domains (e.g., travel) or action types (e.g., image editing). Offering a practical mechanism to encode preferences and subjective evaluation criteria in routing decisions. Today we are extending that approach to Claude Code via Arch Gateway[1], bringing multi-LLM access into a single CLI agent with two main benefits: Model Access: Use Claude Code alongside Grok, Mistral, Gemini, DeepSeek, GPT or local models via Ollama. Preference-aligned routing: Assign different models to specific coding tasks, such as \u2013 Code generation \u2013 Code reviews and comprehension \u2013 Architecture and system design \u2013 Debugging Sample config file to make it all work. llm_providers: # Ollama Models - model: ollama/gpt-oss:20b default: true base_url: http://host.docker.internal:11434 # OpenAI Models - model: openai/gpt-5-2025-08-07 access_key: $OPENAI_API_KEY routing_preferences: - name: code generation description: generating new code snippets, functions, or boilerplate based on user prompts or requirements - model: openai/gpt-4.1-2025-04-14 access_key: $OPENAI_API_KEY routing_preferences: - name: code understanding description: understand and explain existing code snippets, functions, or libraries Why not route based on public benchmarks? Most routers lean on performance metrics \u2014 public benchmarks like MMLU or MT-Bench, or raw latency/cost curves. The problem: they miss domain-specific quality, subjective evaluation criteria, and the nuance of what a \u201cgood\u201d response actually means for a particular user. They can be opaque, hard to debug, and disconnected from real developer needs. [1] Integrated natively via Arch: https://github.com/katanemo/archgw [2] Claude Code support: https://github.com/katanemo/archgw/tree/main/demos/use_cases/claude_code_router"
    },
    {
      "title": "Fear of AI-driven job displacement nearly doubles in a year: KPMG",
      "author": "MetaKnowing",
      "url": "https://www.reddit.com/r/artificial/comments/1pah6ht/fear_of_aidriven_job_displacement_nearly_doubles/",
      "published": 1764505852.0,
      "thumbnail": "https://external-preview.redd.it/zpSTEzk6fR-GkrOTfby5tHCILKGfmK9PZqap0ot2NPY.jpeg?width=640&crop=smart&auto=webp&s=3f650ea66b8b0af34f9493e49807338e53719029",
      "external_url": "https://finance.yahoo.com/news/fear-ai-driven-job-displacement-082338537.html",
      "site_name": "Yahoo Finance",
      "favicon": "https://s.yimg.com/cv/apiv2/default/finance/favicon-180x180.png",
      "description": "The finding comes as two U.S. senators are pushing legislation that would require some AI-related layoffs\u00a0to be reported to the Labor Department."
    },
    {
      "title": "Leak confirms OpenAI is preparing ads on ChatGPT for public roll out",
      "author": "esporx",
      "url": "https://www.reddit.com/r/artificial/comments/1p9rpxd/leak_confirms_openai_is_preparing_ads_on_chatgpt/",
      "published": 1764430254.0,
      "thumbnail": "https://external-preview.redd.it/3eeKlqyQKOZBxccyamJs3jmJ0pmw7YfqjzgTMNl2Zzg.jpeg?width=640&crop=smart&auto=webp&s=8763643d66e2f1eacb6e710428111b1abc6d1983",
      "external_url": "https://www.bleepingcomputer.com/news/artificial-intelligence/leak-confirms-openai-is-preparing-ads-on-chatgpt-for-public-roll-out/",
      "site_name": "BleepingComputer",
      "favicon": "https://www.bleepstatic.com/favicon/bleeping.ico",
      "description": "OpenAI is now internally testing 'ads' inside ChatGPT that could redefine the web economy."
    },
    {
      "title": "Perplexity permabanned me in their official sub for citing their own documentation to expose \"Deep Research\" false advertising and massive downgrade.",
      "author": "somnolentjam90",
      "url": "https://www.reddit.com/r/artificial/comments/1pawnrw/perplexity_permabanned_me_in_their_official_sub/",
      "published": 1764544707.0,
      "thumbnail": null,
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": "I am writing this as a warning to anyone paying for Perplexity Pro expecting the advertised \"Deep Research\" capabilities. TL;DR: I proved, using Perplexity's own active documentation and official launch blog, that their \"Deep Research\" agent is severely throttled and not meeting its contractual specifications. The community validated my findings (my post reached 280+ upvotes, 65 comments, 100+ shares, and reached the top of the sub's front page). Instead of addressing the issue, the moderators permanently banned me and removed the thread to silence the discussion. The Full Story: I have been a Pro subscriber specifically for the \"Deep Research\" feature, which is sold as an \"Autonomous Agent\" that \"reads hundreds of sources\" and takes \"4-5 minutes\" to reason through complex tasks and deliver a comprehensive report. To prove that these are the official specs, I am providing both the current live links and archived snapshots from the Wayback Machine (to prove these have been the consistent standard for months and to prevent potential stealth edits). Official Help Center Documentation: [Current Live Link] | [Wayback Machine Snapshot (Sept 8, 2025)] Official Launch Blog: [Current Live Link] | [Wayback Machine Snapshot (Aug 2, 2025)] (Note: I attempted to capture fresh snapshots of the pages today to confirm their current state, but the Wayback Machine is returning errors/incomplete rendering for the new captures. The provided snapshots from Aug/Sept are the most recent stable versions and confirm these specs have been the published standard for months.) Recently (some months), the service degraded massively. My \"Deep Research\" queries were finishing in 30 seconds with only 10-15 sources, essentially behaving like a standard search wrapper but sold at a premium. I posted (here) a detailed analysis on their official subreddit. I didn't attack anyone; I simply compared their Official Help Center Documentation and Launch Blog against the actual Product Output: Advertised Spec: \"Reads hundreds of sources\" / \"Takes 4-5 minutes\". Actual Reality: Reads ~10 sources / Takes ~30 seconds. The community rallied behind my post. 280+ upvotes, 65 comments, 100+ shares, and reached the top of the sub's front page. It became a hub for other users confirming the same throttling. It was a legitimate customer complaint backed by data. Today, I received a Permanent Ban and the thread got deleted. No warning. No explanation of which rule I broke. Just a permanent ban for the 'offense' of holding them accountable to their own written promises. The Takeaway: This confirms that Perplexity is likely throttling compute on their premium features to save costs and is using censorship to hide it. If you rely on Perplexity for your workflow, be careful. They will degrade the product you rely on without warning, and the moment you provide evidence of the decline, they will silence you rather than fix it."
    },
    {
      "title": "Sam Altman: \"We Know How to Build AGI by 2025\"",
      "author": "creaturefeature16",
      "url": "https://www.reddit.com/r/artificial/comments/1p9tg90/sam_altman_we_know_how_to_build_agi_by_2025/",
      "published": 1764434592.0,
      "thumbnail": "https://external-preview.redd.it/hk-yHajNTIOTYXokaicy4LyAloWKDi518GINUq5IwV8.jpeg?width=320&crop=smart&auto=webp&s=3ee67aefa5b45e33913d67850b7b60fa973484e6",
      "external_url": "https://www.youtube.com/watch?v=Cz6cuGKR_Jo",
      "site_name": "youtube.com",
      "favicon": "https://www.youtube.com/s/desktop/a444dc7a/img/favicon.ico",
      "description": "Well, to be fair, he DOES have one month left. After that, will it OK to call him out for the grifter he is? Edit - Since there seem to be some people who aren't aware that this isn't the full interview where he said it: https://youtu.be/xXCBz_8hM9w?t=2772 Interviewer: \"What are you excited about in 2025? What's to come?\" Altman: \"AGI. Excited for that\"."
    },
    {
      "title": "One-Minute Daily AI News 11/29/2025",
      "author": "Excellent-Target-847",
      "url": "https://www.reddit.com/r/artificial/comments/1pa9p2a/oneminute_daily_ai_news_11292025/",
      "published": 1764478662.0,
      "thumbnail": null,
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": "AI helps drive record $11.8 billion in Black Friday online spending.[1] StepFun AI Releases Step-Audio-R1: A New Audio LLM that Finally Benefits from Test Time Compute Scaling.[2] Musk\u2019s xAI to build small solar farm adjacent to Colossus data center.[3] Are you balding? There\u2019s an AI for that.[4] Sources; [1] https://www.reuters.com/business/retail-consumer/us-consumers-spent-118-billion-black-friday-says-adobe-analytics-2025-11-29/ [2] https://www.marktechpost.com/2025/11/29/stepfun-ai-releases-step-audio-r1-a-new-audio-llm-that-finally-benefits-from-test-time-compute-scaling/ [3] https://techcrunch.com/2025/11/26/musks-xai-to-build-small-solar-farm-adjacent-to-colossus-data-center/ [4] https://techcrunch.com/2025/11/26/are-you-balding-theres-an-ai-for-that/"
    },
    {
      "title": "Are we in a GPT-4-style leap that evals can't see?",
      "author": "malderson",
      "url": "https://www.reddit.com/r/artificial/comments/1pajold/are_we_in_a_gpt4style_leap_that_evals_cant_see/",
      "published": 1764513189.0,
      "thumbnail": "https://external-preview.redd.it/aXspl0HBvr8MJ2QT6jpq-nXVSS5C9PHOBz-8ZSXx180.png?width=640&crop=smart&auto=webp&s=50157b2958234942863a61d8b681a14f30c2da52",
      "external_url": "https://martinalderson.com/posts/are-we-in-a-gpt4-style-leap-that-evals-cant-see/",
      "site_name": "Martin Alderson",
      "favicon": "https://martinalderson.com/apple-touch-icon.png",
      "description": "Gemini 3 Pro's design capabilities and Opus 4.5's reduced babysitting needs represent a subtle but significant leap that traditional benchmarks completely miss."
    },
    {
      "title": "Is Humanity's Last Exam a benchmark that measures real intelligence for AGI?",
      "author": "SpecialistBuffalo580",
      "url": "https://www.reddit.com/r/artificial/comments/1paa4sf/is_humanitys_last_exam_a_benchmark_that_measures/",
      "published": 1764480035.0,
      "thumbnail": null,
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": "With Grok 4 and Gemini 3 the models have become really good at the known benchmarks like ARC-AGI and HLE. But is it really a proof of intelligence? Does acing these benchmarks truly show capabilities for original research and real understanding? I ask this because I saw an interview with Demis Hassabis from two months ago ans he said that AGI will come with 50 confidence between 5-10 years. He also called \"nonsense\" to the qualification \"PhD Level\" that some.people attribute to the models."
    },
    {
      "title": "New Research Indicates Positive Results for an Intermediary Empathetic AI Bot To Help People Quicker",
      "author": "am1ury",
      "url": "https://www.reddit.com/r/artificial/comments/1pa9lht/new_research_indicates_positive_results_for_an/",
      "published": 1764478340.0,
      "thumbnail": "https://external-preview.redd.it/3pLM_AlKn6bBL4L8mL03AYoonDzQTQQH4gQtoW7Trzg.jpeg?width=216&crop=smart&auto=webp&s=fb6e66a1ca560f7e20f0aaa29fd8e6cedcf0b867",
      "external_url": "https://doi.org/10.14293/PR2199.002402.v1",
      "site_name": "ScienceOpen",
      "favicon": "https://doi.org/favicon/so/apple-touch-icon.png",
      "description": "<p xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" class=\"first\" dir=\"auto\" id=\"d442289e88\">This research details the creation, implementation, and rigorous analysis (N=5,400)\n            of Opened Mind, an advanced, multimodal AI system designed to provide empathetic mental\n            health support, especially for teens. It addresses common weaknesses in current digital\n            wellness tools, like scalability, accessibility, and data security. The setup uses\n            a zero-storage, client-side data system for maximum privacy. The core combines insights\n            from three input streams: Facial Action Units (FAUs), Vocal Patterns, and Written\n            Sentiment analysis. This emotional profile drives a Generative AI guided by the Emotion\n            Recognition Strategies (ERS) framework, translating clinical insights into actionable\n            responses. Tests covered 12 major languages (English, Spanish, French, German, Italian,\n            Portuguese, Russian, Hindi, Arabic, Japanese, Korean, and Mandarin), showing strong\n            performance with an 88% Macro F1-Score in cross-input emotion detection. Therapeutic\n            responses averaged 4.12/5.0 on the Compassion Index. Statistical checks, including\n            ANOVA and Chi-Squared tests, found no bias in effectiveness by language or interaction\n            mode (p &gt; 0.05). The emergency detection system also achieved 98% accuracy. These\n            findings confirm Opened Mind as a fair, globally viable, and ethical digital mental\n            health tool, ready for human trials.\n         </p>"
    }
  ],
  "fetched_at": "2025-11-30T23:19:21.430123+00:00"
}