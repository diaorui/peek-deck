{
  "subreddit": "robotics",
  "posts": [
    {
      "title": "Sunday Robotics: Collecting Data Through the Memory-Developer Glove Before Building the Humanoid",
      "author": "marwaeldiwiny",
      "url": "https://www.reddit.com/r/robotics/comments/1pf9wv3/sunday_robotics_collecting_data_through_the/",
      "published": 1764976795.0,
      "thumbnail": "https://external-preview.redd.it/cWxrNjVwcmF4ZzVnMbtkBYuAaT2pID18gUmEoHrxBw0Oi--CtM_V6HPif-8k.png?width=640&crop=smart&auto=webp&s=9ce2592a6b294d95ba2654480fa0e1062241b765",
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": "https://youtu.be/UAlm8Z4mfpU"
    },
    {
      "title": "AGIBOT D1 Pro",
      "author": "Nunki08",
      "url": "https://www.reddit.com/r/robotics/comments/1peuynn/agibot_d1_pro/",
      "published": 1764941052.0,
      "thumbnail": "https://external-preview.redd.it/ZGlmbmhkbHR5ZDVnMcmTqcCmyGxlIJwbMAh9zRk_vOBdKNEWQVCUcGUjD1SH.png?width=640&crop=smart&auto=webp&s=8467a4161ee66696616b006012bb7f536eb613b3",
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": "AGIBOT on \ud835\udd4f: AGIBOT D1 Pro/Edu Quadruped Robot is not only a reliable helper for scientific research and education but also an eye-catcher for entertainment companionship and commercial demonstrations\uff5e 3.5m/s fast running, 1-2 hours battery life, IP54 dustproof & waterproof, durable and easy to use!: https://x.com/AgiBot_zhiyuan/status/1996928040182464537"
    },
    {
      "title": "Robot dance Arduino",
      "author": "Archyzone78",
      "url": "https://www.reddit.com/r/robotics/comments/1pfijsr/robot_dance_arduino/",
      "published": 1765003030.0,
      "thumbnail": "https://external-preview.redd.it/Y25rZXhqYTU0ajVnMbOJhgM30O6ZKO08DBReVskKOrZTZnYgzInYnly_IMMn.png?width=640&crop=smart&auto=webp&s=a5d2610b2998c92abb54372438ed197b1ea3537a",
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": null
    },
    {
      "title": "Art installation draws attention for its robot dogs with famous faces",
      "author": "nbcnews",
      "url": "https://www.reddit.com/r/robotics/comments/1pe56c3/art_installation_draws_attention_for_its_robot/",
      "published": 1764867378.0,
      "thumbnail": "https://external-preview.redd.it/cTJ2N2RidXF3NzVnMa2NkyWLusU3EEB1G1quIu5uMib9yhFcaTJpvX4KlXi-.png?width=640&crop=smart&auto=webp&s=5c4b356e7b7139ee64c4e5a27f5c0e40298e7324",
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": null
    },
    {
      "title": "Are we witnessing the end of \u201creal robot data\u201d as the foundation of Embodied AI? Recent results from InternData-A1, GEN-0, and Tesla suggest a shift. (Original post by Felicia)",
      "author": "Individual-Major-309",
      "url": "https://www.reddit.com/r/robotics/comments/1pessi4/are_we_witnessing_the_end_of_real_robot_data_as/",
      "published": 1764934446.0,
      "thumbnail": "https://a.thumbs.redditmedia.com/xYGdExuacIcgGtMT_4UoS63x2i1kRFGFAmyDCxoBwi4.jpg",
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": "For a long time, many robotics teams believed that real robot interaction data was the only reliable foundation for training generalist manipulation models. But real-world data collection is extremely expensive, slow, and fundamentally limited by human labor. Recent results suggest the landscape is changing. Three industry signals stand out: 1. InternData-A1: Synthetic data beats the strongest real-world dataset Shanghai AI Lab\u2019s new paper InternData-A1 (Nov 2025, arXiv) is the first to show that pure simulation data can match or outperform the best real-robot dataset used to train Pi0. The dataset is massive: 630k+ trajectories 7,434 hours 401M frames 4 robot embodiments, 18 skill types, 70 tasks $0.003 per trajectory generation cost One 8\u00d7RTX4090 workstation \u2192 200+ hours of robot data per day Results: On RoboTwin2.0 (49 bimanual tasks): +5\u20136% success over Pi0 On 9 real-world tasks: +6.2% success Sim-to-Real: 1,600 synthetic samples \u2248 200 real samples (\u22488:1 efficiency) The long-held \u201csimulation quality discount\u201d is shrinking fast. 2. GEN-0 exposes the economic impossibility of scaling real-world teleoperation Cross-validated numbers show: Human teleoperation cost per trajectory: $2\u2013$10 Hardware systems: $30k\u2013$40k 1 billion trajectories \u2192 $2\u201310 billion GEN-0\u2019s own scaling law predicts that laundry alone would require 1B interactions for strong performance. https://preview.redd.it/qd8pkcdpfd5g1.png?width=556&format=png&auto=webp&s=1df2607476d3e63f5ca32edae1bf7319d97f1176 Even with Tesla-level resources, this is not feasible. That\u2019s why GEN-0 relies on distributed UMI collection across thousands of sites instead of traditional teleoperation. 3. Tesla\u2019s Optimus shifts dramatically: from mocap \u2192 human video imitation Timeline: 2022\u20132024: Tesla used full-body mocap suits + VR teleop; operators wore ~30 lb rigs, walked 7 hours/day, paid up to $48/hr. May 21, 2025: Tesla confirms:\u201cOptimus is now learning new tasks directly from human videos.\u201d June 2025: Tesla transitions to a vision-only approach, dropping mocap entirely. Their demo showed Optimus performing tasks like trash disposal, vacuuming, cabinet/microwave use, stirring, tearing paper towels, sorting industrial parts \u2014 all claimed to be controlled by a single end-to-end network. 4. So is real robot data obsolete? Not exactly. These developments indicate a shift, not a disappearance: Synthetic data (InternData-A1) is now strong enough to pre-train generalist policies Distributed real data (GEN-0) remains critical for grounding and calibration Pure video imitation (Tesla) offers unmatched scalability but still needs validation for fine manipulation All major approaches still rely on a small amount of real data for fine-tuning or evaluation Open Questions: Where do you think the field is heading? A synthetic-first paradigm? Video-only learning at scale? Hybrid pipelines mixing sim, video, and small real datasets? Or something entirely new? Curious to hear perspectives from researchers, roboticists, and anyone training embodied agents."
    },
    {
      "title": "Chat Interface for Isaac Sim",
      "author": "wasabidino",
      "url": "https://www.reddit.com/r/robotics/comments/1pfa7jb/chat_interface_for_isaac_sim/",
      "published": 1764977565.0,
      "thumbnail": null,
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": null
    },
    {
      "title": "Behind-the-scenes footage from the EngineAI T800 shoot \u2014 a direct response to the CG accusations.",
      "author": "Ready_Device8994",
      "url": "https://www.reddit.com/r/robotics/comments/1peipg7/behindthescenes_footage_from_the_engineai_t800/",
      "published": 1764899968.0,
      "thumbnail": "https://external-preview.redd.it/vopCp3AoP3agRM_vVjx1qGQ2dEK42KQd5nQEj5DdiQA.jpeg?width=320&crop=smart&auto=webp&s=b4c4505fe2c220f8942da9db848c634ecdba635b",
      "external_url": "https://www.youtube.com/watch?v=VoytjBgpG28",
      "site_name": "youtube.com",
      "favicon": "https://www.youtube.com/s/desktop/db7db827/img/favicon.ico",
      "description": "Enjoy the videos and music you love, upload original content, and share it all with friends, family, and the world on YouTube."
    },
    {
      "title": "ROS News for the Week of December 2nd, 2025",
      "author": "OpenRobotics",
      "url": "https://www.reddit.com/r/robotics/comments/1pf5ccu/ros_news_for_the_week_of_december_2nd_2025/",
      "published": 1764965493.0,
      "thumbnail": "https://external-preview.redd.it/ZRxQSYvz7RK70LarVkZ0JsNr2rRueei96seBmDJoatU.gif?width=640&crop=smart&s=480960cabf1c914aa731ede8c40bec3c3fb4a693",
      "external_url": "https://discourse.openrobotics.org/t/ros-news-for-the-week-of-december-2nd-2025/51298",
      "site_name": "Open Robotics Discourse",
      "favicon": "https://us1.discourse-cdn.com/flex022/uploads/ros/optimized/3X/4/4/4487d2db196c8ca556e8bfac980ed3850ba5cbd5_2_180x180.png",
      "description": "ROS News for the Week of December 2nd, 2025     ROSCon 2025 videos are now available! If you want a quick summary of the event I put together ROSCon 2025 Recap for the OpenCV Weekly Webinar.       For Giving Tuesday we put together a new campaign for ROS users to become a become a Build Farm Backer. If you\u2019ve every saved a few minutes by running sudo apt install ros-kilted-* instead of compiling from source we would love it if you helped cover our compute costs. Also, for the first time ever, we..."
    },
    {
      "title": "Making a Marauder's Map from Harry Potter",
      "author": "davesarmoury",
      "url": "https://www.reddit.com/r/robotics/comments/1pf1agl/making_a_marauders_map_from_harry_potter/",
      "published": 1764956101.0,
      "thumbnail": "https://external-preview.redd.it/lkbyF5afhW6Htup7fUyNQVABCSEpJ946WVXQNrql7uM.jpeg?width=320&crop=smart&auto=webp&s=7bd8c748c2ede63e1e653ef9114a146b3f7c00ea",
      "external_url": "https://www.youtube.com/watch?v=dO32ImnsX-4",
      "site_name": "youtube.com",
      "favicon": "https://www.youtube.com/s/desktop/db7db827/img/favicon.ico",
      "description": "Arthur C. Clarke said \"Any sufficiently advanced technology is indistinguishable from magic\". This is the perfect example of that. We are taking a magical map that previously could only exist in a magical world and bringing it to life using robots, DeepStream, and multiple A6000 GPUs!"
    },
    {
      "title": "Marc Raibert on Why Robotics Needs More Transparency",
      "author": "Responsible-Grass452",
      "url": "https://www.reddit.com/r/robotics/comments/1pea59d/marc_raibert_on_why_robotics_needs_more/",
      "published": 1764878463.0,
      "thumbnail": "https://external-preview.redd.it/czZ0M2RhcXZrODVnMXDFs25VAGMQ7jD7P7IJtotqHhQXTfEBoVTtdkOU5sNG.png?width=640&crop=smart&auto=webp&s=1ce77a3ba16429df69e330a6878c87a7c4a26597",
      "external_url": null,
      "site_name": null,
      "favicon": null,
      "description": "Marc Raibert talks about how robotics demos usually show only the polished successes, even though most of the real progress comes from the failures. The awkward grasps, strange edge cases, and completely unexpected behaviors are where engineers learn the most. He points out that hiding all of that creates a distorted picture of what robotics development actually looks like. What makes his take interesting is that it comes from someone who helped define the modern era of legged robots. Raibert has been around long enough to see how public perception shifts when the shiny videos overshadow the grind behind them. His push for more openness feels less like criticism and more like a reminder of what drew so many people into robotics in the first place: the problem solving, the iteration, and the weird in-between moments where breakthroughs usually begin."
    }
  ],
  "fetched_at": "2025-12-06T07:12:03.972809+00:00"
}